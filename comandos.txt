

									COMANDOS UTILIZADOS DURANTE A TRILHA

**** iniciando o zookeeper:
windows: bin\windows\zookeeper-server-start.bat config\zookeeper.properties
linux: bin/zookeeper-server-start.sh config/zookeeper.properties



***** iniciando o kafka:
windows:bin\windows\kafka-server-start.bat config\server.properties
linux: bin/kafka-server-start.sh config/server.properties

Obs: no linux sempre se usa os comandos com .sh no windows dentro da pasta bin sempre se usa os comandos .bat


***** criando um tópico no kafka:
windows: bin\windows\kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic LOJA_NOVO_PEDIDO
linux: bin/kafka-topics.sh --create --bootstrap-server localhost:9082 --replication-factor 1 --partitions 1 --topic LOJA_NOVO_PEDIDO 




**** mostrar os tópicos criados:
linux: bin/kafka-topics.sh --list --bootstrap-server localhost:9092 
windows: bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092




****** rodando um produtor de msgs(que produz as msgs):
linux: bin/kafka-console-producer.sh --broker-list localhost:9092  --topic LOJA_NOVO_PEDIDO 
windows: \bin\windows\kafka-console-producer.bat --broker-list localhost:9092 --topic LOJA_NOVO_PEDIDO





****** consumindo um tópico desde a primeira msg que está armazenada:
linux: bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic LOJA_NOVO_PEDIDO --from-beginning 
windows: bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic LOJA_NOVO_PEDIDO --from-beginning




********** descrevendo os tópicos:
linux: bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe
windows: bin\windows\kafka-topics.bat --bootstrap-server localhost:9092 --describe



********** alterar um tópico (número de partição):

linux: bin/kafka-topics.sh --alter --bootstrap-server localhost:9092 --topic ECOMMERCE_NEW_ORDER --partitions 3 -- esse funcionou devido a versão do kafka

windows: bin\windows\kafka-topics.bat --alter --zookeeper localhost:9092 --topic ECOMMERCE_NEW_ORDER --partitions 3




******* analisar os grupos de consumo:

windows: bin\windows\kafka-consumer-groups.bat --all-groups --bootstrap-server localhost:9092 --describe
linux: bin/kafka-consumer-groups.sh --all-groups --bootstrap-server localhost:9092 --describe


*********** alterar a para que o broker se replique em outro broker:
obs: o fator de replicação não pode ser alterado com o comando alter, o kafka não permite Option "[replication-factor]" can't be used with option "[alter]"
Option                                   Description               
linux: bin/kafka-topics.sh --zookeeper  localhost:2181 --alter --topic ECOMMERCE_NEW_ORDER --partitions 3 --replication-factor 2 
bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic ECOMMERCE_NEW_ORDER --partitions 3 --replication-factor 2 --- esse deu certo devido a versão utilizada do kafka



*********** adicionando uma nova propriedade de replicação no config/server.properties:


***** conferindo todos os tópicos pelo zookeeper:
linux: bin/kafka-topics.sh --describe --zookeeper localhost:2181


*************** No #kafka não existe funcionalidade para apagar os eventos. O que temos é a polícia de limpeza configurada em nível tópico, 
que está relacionado com a retenção: retention.ms e retention.bytes:
	# Limpeza por eliminação
	cleanup.policy=delete

	# Limpeza por compactação
	cleanup.policy=compact

	# Ambas
	cleanup.policy=delete,compact


link de explicação do kafka transaction: medium.com/@mykidong/kafka-transaction-56f022af1b0c
link dos repositórios remotos utilizados na trilha da alura: https://github.com/orgs/alura-cursos/repositories?type=all&q=kafka

**** Configurando o confluent para executar o confluent kafka
* após baixar e extrair o arquivo configurar as duas variáveis de ambiente da seguinte forma:
variável confluent_home -> export CONFLUENT_HOME=/l/disk0/sanara/confluent/confluent-7.6.0
variável path -> export PATH=$CONFLUENT_HOME/bin:$PATH

** para executar o confluent : confluent local services start

**** Caso haja erro na inicialização é necessário instalar a versão 8 ou 11 do java e configurar o caminho para o confluent  seguir os passos:
* instalar a versão 11 do java
* selecionar a versão que queira usar o java através do comando : sudo update-alternatives --config java
* copie esse caminho desejado ( no caso o java 11) do arquivo e altere a variavel de ambiente do JAVA_HOME para apontar para o caminho da instalação
* para alterar você pode usar o nano através do comando : sudo nano /etc/environment ou outro editor de texto
e colocar a variaavel assim: JAVA_HOME="/usr/lib/jvm/java-11-openjdk-amd64"
* salve o arquivo e saia do editor 
* depois recarregue as alterações que vc fez com o comando : source /etc/environment
* para conferir se deu certo digite o comando echo $JAVA_HOME e deverá aparecer o caminho configurado

** após essa configuração executar novamente o comando :  confluent local services start


link do control center: localhost:9021/clusters/


**** comandos para instalar o java através do sdkman.io:
instalação: 
curl -s "https://get.sdkman.io" | bash
source "$HOME/.sdkman/bin/sdkman-init.sh"
sdk version

* ver toas as versões java disponiveis: sdk java list





